{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Task_3_[student].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuWDYx7ZaXh2"
      },
      "source": [
        "# Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upBn5zZRbBCw"
      },
      "source": [
        "Let's implement a Neural Network, which contains a stack of 2 LSTMs, both processing sequences, 2 Fully Connected layers and 1-3 Dropouts. You can use max. one additional convolutional layer, if needed. Let's use Sequential API, Adam optimizer and MNIST dataset. Use properly the train, val and test splits presented below. Your model should obtain at least 98.5% accuracy on both val and test sets. Then, let's implement the Grad-CAM algorithm to visualize a class activation heatmap (function get_gradcam_heatmap)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83tGAtx4WNXM"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_val, y_val = x_train[-10000:], y_train[-10000:]\n",
        "x_train, y_train = x_train[:-10000], y_train[:-10000]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4XgyeLyX5aG"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "x_train = tf.cast(x_train, tf.float32)\r\n",
        "x_test = tf.cast(x_test, tf.float32)\r\n",
        "x_val = tf.cast(x_val, tf.float32)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1Jq7ounX7vE"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical   \r\n",
        "\r\n",
        "y_train = to_categorical(y_train, num_classes=10)\r\n",
        "y_val = to_categorical(y_val, num_classes=10)\r\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrCzo7CDYgrD"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\r\n",
        "x_val = np.reshape(x_val, (len(x_val), 28, 28, 1))\r\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7d3qYHnWinx"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dropout, LSTM, Dense, Flatten, Conv2D, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape = (28,28,1)))\n",
        "model.add(Conv2D(16, (4,4), padding='same', activation='relu'))\n",
        "model.add(Reshape((28,448)))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(LSTM(196))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation='sigmoid'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vEGC0fVYNQc"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q39GMoJqYP8l",
        "outputId": "523bbf41-c78b-4dc5-81c7-cc41d531c530"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=256, epochs=8, validation_data=(x_val, y_val))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "196/196 [==============================] - 9s 22ms/step - loss: 0.8649 - acc: 0.7101 - val_loss: 0.1641 - val_acc: 0.9530\n",
            "Epoch 2/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.1575 - acc: 0.9536 - val_loss: 0.0910 - val_acc: 0.9736\n",
            "Epoch 3/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0942 - acc: 0.9736 - val_loss: 0.0714 - val_acc: 0.9789\n",
            "Epoch 4/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0830 - acc: 0.9753 - val_loss: 0.0605 - val_acc: 0.9820\n",
            "Epoch 5/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0606 - acc: 0.9821 - val_loss: 0.0666 - val_acc: 0.9824\n",
            "Epoch 6/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0483 - acc: 0.9854 - val_loss: 0.0474 - val_acc: 0.9864\n",
            "Epoch 7/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0446 - acc: 0.9872 - val_loss: 0.0598 - val_acc: 0.9855\n",
            "Epoch 8/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0398 - acc: 0.9882 - val_loss: 0.0479 - val_acc: 0.9882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5a5e37b898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17utS_Cac2kQ"
      },
      "source": [
        "model.optimizer.learning_rate = 1e-5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lOHFohUizcF",
        "outputId": "cec8aca2-bdef-4828-d4c6-51a97df5a3e3"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=256, epochs=8, validation_data=(x_val, y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0254 - acc: 0.9926 - val_loss: 0.0436 - val_acc: 0.9884\n",
            "Epoch 2/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0421 - val_acc: 0.9884\n",
            "Epoch 3/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 0.0413 - val_acc: 0.9885\n",
            "Epoch 4/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0177 - acc: 0.9952 - val_loss: 0.0407 - val_acc: 0.9891\n",
            "Epoch 5/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.0404 - val_acc: 0.9893\n",
            "Epoch 6/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0152 - acc: 0.9960 - val_loss: 0.0402 - val_acc: 0.9895\n",
            "Epoch 7/8\n",
            "196/196 [==============================] - 3s 17ms/step - loss: 0.0147 - acc: 0.9960 - val_loss: 0.0401 - val_acc: 0.9896\n",
            "Epoch 8/8\n",
            "196/196 [==============================] - 3s 16ms/step - loss: 0.0134 - acc: 0.9965 - val_loss: 0.0401 - val_acc: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5ab77cdcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0MiqEjRbTGM",
        "outputId": "59c1bd07-962e-41f6-db21-d9b9d95bf778"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0390 - acc: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03899970278143883, 0.989799976348877]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQVlYr2y0z18"
      },
      "source": [
        "def get_gradcam_heatmap( model, img ):\n",
        "  from tensorflow.keras.models import Model\n",
        "  #sectioning model\n",
        "\n",
        "  #model with the last convolutional network\n",
        "  conv_model = Model(model.inputs, model.layers[0].output)\n",
        "\n",
        "  #model with task-specific network (the rest of the layers)\n",
        "  ts_input = Input(shape=model.layers[0].output.shape[1:])\n",
        "  x = ts_input\n",
        "  for layer in model.layers[1:]:\n",
        "    x = layer(x)\n",
        "  ts_model = Model(ts_input, x)\n",
        "\n",
        "  with tf.GradientTape() as g:\n",
        "    conv_out = conv_model(np.expand_dims(img, axis=0))\n",
        "    g.watch(conv_out)\n",
        "    preds = ts_model(conv_out)\n",
        "    pred_channel = preds[:, tf.argmax(preds[0])]\n",
        "\n",
        "  grads = g.gradient(target=pred_channel, sources=conv_out)[0]\n",
        "\n",
        "  grads = (np.asarray(grads).sum(axis=(0,1)))/(28*28)\n",
        "  conv_out = np.asarray(conv_out).copy().sum(axis=0)\n",
        "\n",
        "  for i in range(grads.shape[-1]):\n",
        "    conv_out[:,:,i] *= grads[i]\n",
        "\n",
        "  heatmap = tf.keras.activations.relu(conv_out.sum(axis=2))\n",
        "\n",
        "  return heatmap"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "gJtv7P151MOo",
        "outputId": "1b8a428c-3e27-4b47-d9e2-4c193748ba03"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "heatmap = get_gradcam_heatmap( model, x_test[0])\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yevNfFcyfHBT"
      },
      "source": [
        "## Save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8yrTULaKdd-"
      },
      "source": [
        "model.save('Weronika_Skibicka_410952', save_format='h5')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8XImInBfJaw"
      },
      "source": [
        "## Submission\n",
        "You need to send by the deadline:\n",
        "- the trained model with architecture and weights (as YourFirstName_YourSourname_Indeks.h5 file).\n",
        "- and jupyter notebook (ipynb file) with all outputs and training logs (as YourFirstName_YourSourname_Indeks.ipynb file). The trained model should be reproducible by running Runtime -> Run all."
      ]
    }
  ]
}